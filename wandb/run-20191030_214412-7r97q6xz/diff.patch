diff --git a/aae_filter_test.ipynb b/aae_filter_test.ipynb
index d4f1d0e..f8bdec2 100644
--- a/aae_filter_test.ipynb
+++ b/aae_filter_test.ipynb
@@ -2,7 +2,7 @@
  "cells": [
   {
    "cell_type": "code",
-   "execution_count": 16,
+   "execution_count": 33,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -32,7 +32,8 @@
     "from scipy.stats import entropy\n",
     "from scipy.stats import norm, kstest\n",
     "from scipy.spatial.distance import jensenshannon as jsd\n",
-    "\n"
+    "\n",
+    "import seaborn as sns"
    ]
   },
   {
@@ -44,7 +45,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 17,
+   "execution_count": 2,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -55,7 +56,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 18,
+   "execution_count": 3,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -84,16 +85,23 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 19,
+   "execution_count": 4,
    "metadata": {},
    "outputs": [
     {
+     "name": "stdout",
+     "output_type": "stream",
+     "text": [
+      "WARNING:tensorflow:From /home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Colocations handled automatically by placer.\n"
+     ]
+    },
+    {
      "name": "stderr",
      "output_type": "stream",
      "text": [
       "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
-      "  warnings.warn('No training configuration found in save file: '\n",
-      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
       "  warnings.warn('No training configuration found in save file: '\n"
      ]
     }
@@ -104,7 +112,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 20,
+   "execution_count": 5,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -119,7 +127,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 6,
    "metadata": {},
    "outputs": [],
    "source": [
@@ -135,73 +143,6 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 6,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "def anomaly_score(img_wd, batch, input_dim):\n",
-    "    # TODO: docsting\n",
-    "    data_loader = ImageDataGenerator(\n",
-    "        rescale=1. / 255,\n",
-    "        featurewise_center=True,\n",
-    "        featurewise_std_normalization=True,\n",
-    "        shear_range=0.2,\n",
-    "        zoom_range=0.2,\n",
-    "        horizontal_flip=True)\n",
-    "\n",
-    "    train_data = data_loader.flow_from_directory(\n",
-    "        img_wd,\n",
-    "        target_size=(input_dim[0], input_dim[0]),\n",
-    "        batch_size=batch,\n",
-    "        class_mode='input')\n",
-    "    \n",
-    "    batch_index = 0\n",
-    "    discriminator_batch_losses = []\n",
-    "    while batch_index <= train_data.batch_index:\n",
-    "        data = train_data.next()\n",
-    "        data_list = data[0]\n",
-    "        data_size = len(data_list)\n",
-    "\n",
-    "        fake_latent = encoder.predict(data_list)\n",
-    "        discriminator_input = np.concatenate((fake_latent, np.random.randn(data_size, latent_dim) * 5.))\n",
-    "        discriminator_labels = np.concatenate((np.zeros((data_size, 1)), np.ones((data_size, 1))))\n",
-    "        discriminator_history = discriminator.evaluate(x=discriminator_input, y=discriminator_labels)\n",
-    "\n",
-    "            \n",
-    "        batch_index = batch_index + 1\n",
-    "        discriminator_batch_losses.append(discriminator_history[0])\n",
-    "    \n",
-    "    \n",
-    "    \n",
-    "    \n",
-    "    ae_res = autoencoder.evaluate_generator(train_data)[0]\n",
-    "    adv_res = np.mean(discriminator_batch_losses)\n",
-    "    \n",
-    "    \n",
-    "    \n",
-    "    \n",
-    "    if draw:\n",
-    "        fig = plt.figure(figsize=(5 * len(samples), 5))\n",
-    "        gs = gridspec.GridSpec(1, len(samples))\n",
-    "        for i, sample in enumerate(samples):\n",
-    "            ax = plt.Subplot(fig, gs[i])\n",
-    "            ax.imshow((sample[\"image\"] * 255.).astype(\"int\"), cmap='gray')\n",
-    "            ax.set_xticks([])\n",
-    "            ax.set_yticks([])\n",
-    "            ax.set_aspect('equal')\n",
-    "            ax.set_title(sample[\"title\"])\n",
-    "            fig.add_subplot(ax)\n",
-    "        plt.show(block=False)\n",
-    "        \n",
-    "    \n",
-    "    print('Class: {}\\nae_loss: {}\\nadv_loss: {}'.format(cell_pheno, ae_res, adv_res))\n",
-    "    return [ae_res, adv_res]\n",
-    "    \n",
-    "        "
-   ]
-  },
-  {
-   "cell_type": "code",
    "execution_count": 7,
    "metadata": {},
    "outputs": [
@@ -236,42 +177,17 @@
    "metadata": {},
    "outputs": [
     {
-     "data": {
-      "text/plain": [
-       "['/home/aogorodnikov/test/polarity/Pt04_r01c01_f02_0032.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f08_0257.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f09_0342.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f10_0234.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f10_0236.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f11_0224.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f13_0716.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f14_0961.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f15_0732.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f16_0516.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f16_0548.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f16_0550.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f16_0633.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f17_0252.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f17_0557.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f17_0563.tif',\n",
-       " '/home/aogorodnikov/test/polarity/Pt04_r01c01_f17_0604.tif']"
-      ]
-     },
-     "execution_count": 8,
-     "metadata": {},
-     "output_type": "execute_result"
+     "name": "stderr",
+     "output_type": "stream",
+     "text": [
+      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
+      "  warnings.warn('This ImageDataGenerator specifies '\n",
+      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
+      "  warnings.warn('This ImageDataGenerator specifies '\n"
+     ]
     }
    ],
    "source": [
-    "data_in.filepaths[:17]"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": null,
-   "metadata": {},
-   "outputs": [],
-   "source": [
     "batch_index = 0\n",
     "\n",
     "data = data_in.next()\n",
@@ -284,27 +200,11 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 10,
-   "metadata": {},
-   "outputs": [],
-   "source": [
-    "lol = [mse_batch(data_list[x], ae_pred[x], input_dim) for x in range(len(ae_pred))]"
-   ]
-  },
-  {
-   "cell_type": "code",
-   "execution_count": 11,
+   "execution_count": 25,
    "metadata": {},
    "outputs": [],
    "source": [
-    "def jsd_batch(latent_x, latent_dim):\n",
-    "    '''\n",
-    "    Function to compute adversarial loss\n",
-    "    :param latent_x: encoded latent space\n",
-    "    :return: KL divergence b/w prior\n",
-    "    '''\n",
-    "    prior = np.random.randn(latent_dim) * 5.\n",
-    "    return jsd(norm.pdf(latent_x), norm.pdf(prior))"
+    "lol1 = [mse_batch(data_list[x], ae_pred[x], input_dim) for x in range(len(ae_pred))]"
    ]
   },
   {
@@ -335,7 +235,27 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 14,
+   "execution_count": 31,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "0.0025168"
+      ]
+     },
+     "execution_count": 31,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "round(lol[0], 7)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 34,
    "metadata": {},
    "outputs": [
     {
diff --git a/aae_test.ipynb b/aae_test.ipynb
index 276e7d6..0cbac80 100644
--- a/aae_test.ipynb
+++ b/aae_test.ipynb
@@ -142,7 +142,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 3,
+   "execution_count": 1,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -195,7 +195,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 2,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -203,7 +203,7 @@
    },
    "outputs": [],
    "source": [
-    "def create_model(input_dim, latent_dim, verbose=False, save_graph=False, conv=True,\n",
+    "def create_model(input_dim, latent_dim, verbose=False, save_graph=False, conv=False,\n",
     "                 adversarial=True):\n",
     "    '''\n",
     "    Creates model\n",
@@ -300,7 +300,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 3,
    "metadata": {
     "colab": {},
     "colab_type": "code",
@@ -385,7 +385,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 21,
+   "execution_count": 4,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -411,7 +411,7 @@
      "data": {
       "text/html": [
        "\n",
-       "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/gvaihir_ucsf/uncategorized/runs/vdzh961d\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
+       "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/gvaihir_ucsf/image_sudoku/runs/7r97q6xz\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
        "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
        "    "
       ],
@@ -419,33 +419,29 @@
        "<IPython.core.display.HTML object>"
       ]
      },
-     "metadata": {
-      "tags": []
-     },
+     "metadata": {},
      "output_type": "display_data"
     },
     {
      "data": {
       "text/plain": [
-       "W&B Run: https://app.wandb.ai/gvaihir_ucsf/uncategorized/runs/vdzh961d"
+       "W&B Run: https://app.wandb.ai/gvaihir_ucsf/image_sudoku/runs/7r97q6xz"
       ]
      },
-     "execution_count": 21,
-     "metadata": {
-      "tags": []
-     },
+     "execution_count": 4,
+     "metadata": {},
      "output_type": "execute_result"
     }
    ],
    "source": [
-    "img_wd = \"data/\"\n",
+    "img_wd = \"/home/aogorodnikov/data_aae\"\n",
     "batch = 56\n",
     "input_dim = (104,104,3)\n",
     "latent_dim = 32\n",
     "epoch = 10\n",
     "conv=True\n",
     "adversarial=True\n",
-    "out=\"aae/\"\n",
+    "out=\"~/aae/\"\n",
     "# initialize monitoring with WandB\n",
     "wandb.init()\n",
     "\n",
@@ -455,7 +451,7 @@
   },
   {
    "cell_type": "code",
-   "execution_count": 22,
+   "execution_count": 5,
    "metadata": {
     "colab": {
      "base_uri": "https://localhost:8080/",
@@ -481,16 +477,19 @@
      "name": "stdout",
      "output_type": "stream",
      "text": [
+      "WARNING:tensorflow:From /home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
+      "Instructions for updating:\n",
+      "Colocations handled automatically by placer.\n",
       "Autoencoder Architecture\n",
-      "Model: \"model_7\"\n",
+      "Model: \"model_1\"\n",
       "_________________________________________________________________\n",
       "Layer (type)                 Output Shape              Param #   \n",
       "=================================================================\n",
-      "input_7 (InputLayer)         (None, 104, 104, 3)       0         \n",
+      "input_1 (InputLayer)         (None, 104, 104, 3)       0         \n",
       "_________________________________________________________________\n",
-      "sequential_10 (Sequential)   (None, 32)                22069760  \n",
+      "sequential_1 (Sequential)    (None, 32)                22069760  \n",
       "_________________________________________________________________\n",
-      "sequential_11 (Sequential)   (None, 104, 104, 3)       22053091  \n",
+      "sequential_2 (Sequential)    (None, 104, 104, 3)       22053091  \n",
       "=================================================================\n",
       "Total params: 44,122,851\n",
       "Trainable params: 44,111,843\n",
@@ -498,15 +497,15 @@
       "_________________________________________________________________\n",
       "None\n",
       "Discriminator Architecture\n",
-      "Model: \"sequential_12\"\n",
+      "Model: \"sequential_3\"\n",
       "_________________________________________________________________\n",
       "Layer (type)                 Output Shape              Param #   \n",
       "=================================================================\n",
-      "dense_34 (Dense)             (None, 2704)              89232     \n",
+      "dense_7 (Dense)              (None, 2704)              89232     \n",
       "_________________________________________________________________\n",
-      "dense_35 (Dense)             (None, 2704)              7314320   \n",
+      "dense_8 (Dense)              (None, 2704)              7314320   \n",
       "_________________________________________________________________\n",
-      "dense_36 (Dense)             (None, 1)                 2705      \n",
+      "dense_9 (Dense)              (None, 1)                 2705      \n",
       "=================================================================\n",
       "Total params: 14,812,514\n",
       "Trainable params: 7,406,257\n",
@@ -514,15 +513,15 @@
       "_________________________________________________________________\n",
       "None\n",
       "Generator Architecture\n",
-      "Model: \"model_8\"\n",
+      "Model: \"model_2\"\n",
       "_________________________________________________________________\n",
       "Layer (type)                 Output Shape              Param #   \n",
       "=================================================================\n",
-      "input_8 (InputLayer)         (None, 104, 104, 3)       0         \n",
+      "input_2 (InputLayer)         (None, 104, 104, 3)       0         \n",
       "_________________________________________________________________\n",
-      "sequential_10 (Sequential)   (None, 32)                22069760  \n",
+      "sequential_1 (Sequential)    (None, 32)                22069760  \n",
       "_________________________________________________________________\n",
-      "sequential_12 (Sequential)   (None, 1)                 7406257   \n",
+      "sequential_3 (Sequential)    (None, 1)                 7406257   \n",
       "=================================================================\n",
       "Total params: 29,476,017\n",
       "Trainable params: 22,058,752\n",
@@ -535,7 +534,7 @@
      "name": "stderr",
      "output_type": "stream",
      "text": [
-      "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
+      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
       "  'Discrepancy between trainable weights and collected trainable'\n"
      ]
     }
@@ -1227,9 +1226,9 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.6.8"
+   "version": "3.7.3"
   }
  },
  "nbformat": 4,
- "nbformat_minor": 2
+ "nbformat_minor": 4
 }
diff --git a/plan.ipynb b/plan.ipynb
index e70d806..519b1cb 100644
--- a/plan.ipynb
+++ b/plan.ipynb
@@ -587,7 +587,10 @@
     "\n",
     "# ToDo  \n",
     "1. Filter out negatives on for plate 4 as a test and re-cluster  \n",
-    "2. Do also grid for reconstruction"
+    "2. Do also grid for reconstruction  \n",
+    "\n",
+    "# Update 191030  \n",
+    "ACAE raedy for predictions. Tested on classes - seems that it does not very well differentiate between phenotype and normal cells (see `aae_filter_inspect`). Create a deeper net and increase number of latent dimenstions."
    ]
   },
   {
