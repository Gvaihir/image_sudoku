{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Image processing for pheno-sudoku  \n",
    "### Plan  \n",
    "\n",
    "1. Ground truth:  \n",
    "    a) Bin image to 4 chunks of 256x256;  \n",
    "    b) Code for random selection of images from the screen (x20); perform LoG on channel 3, make RGB image, R/G/B = 80/10/10 (R = ch3, membrane); Code how to normalize channels for all the images;  \n",
    "    c) create masks.  \n",
    "2. Training of StarDist  \n",
    "3. Segmentation \n",
    "    a) Import (use random selection)    \n",
    "    b) Predict centroids and vertices  \n",
    "    c) Estimate surface  \n",
    "    d) Remove polygons under threshold  \n",
    "    e) Export single cell img  \n",
    "4. Clustering with unsupervised CNN  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "When trained unsupervised net...  \n",
    "1. visualize clusters\n",
    "2. show normalized mutual information increase\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**04/24/19 Update**  \n",
    "All plates but 3:5,9,14 finished.  \n",
    "\n",
    "\n",
    "### Deepcluster  \n",
    "AlexNet arch was trained on nuclear crops from 1 field of view from every well of Pt04. For 100 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL instance setup\n",
    "\n",
    "```bash\n",
    "conda create --name imgSudoku pandas numpy scipy seaborn opencv scikit-learn matplotlib tensorflow-gpu\n",
    "conda activate imgSudoku\n",
    "\n",
    "wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/cuda-repo-ubuntu1604_10.1.105-1_amd64.deb\n",
    "\n",
    "sudo dpkg -i cuda-repo-ubuntu1604_10.1.105-1_amd64.deb\n",
    "sudo apt-key adv --fetch-keys http://developer.download.nvidia.com/compute/cuda/repos/ubuntu1604/x86_64/7fa2af80.pub\n",
    "sudo apt-get update\n",
    "sudo apt-get install cuda\n",
    "\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agenda for 05/09/19  \n",
    "**Synopsis:** we performed an image based screen on CRISPR-Cas9 induced knock outs of druggable genes. To analyze the phenotypic complexity of each knockout, I extracted single cell (nucleus) images using deep learning based segmentation. Total scale of data resulted in over 76 million single-nucleus images. To analyze phenotypic changes I used unsupervised deep learning and clustered the data (using deepcluster to train AlexNet model) in 100 arbitrary clusters. AlexNet was trained using 1 million single nucleus images.  \n",
    "\n",
    "**Questions for a downstream analysis of the full dataset (alternatives):**  \n",
    "1. Should I re-configure deepcluster-trained AlexNet to perform classification tasks on N pseudo labels? How to approach? I can remove the top layer and use input from last conv layer (4096 features) and map them to N clusters. Do you have recommendations how to re-arrange AlexNet in this case?  \n",
    "2. I can extract 4096 features from conv5 for every image and perform the clustering. How should I go about this number of observations - loading full dataset and doing PCA seems infeasible? There are ways for incremental PCA clustering, not sure if they work with downstream UMAP. Also there is an online learning... What are the prerequisites to use either?  \n",
    "3. How would you recommend to organize the infrastructure of this data? SPARK, Hadoop, SQL?  \n",
    "4. Which stastistics to use for cluster evaluation?\n",
    "5. Any recommendation of demonstrating interpretability of clustering net? Feature importance map?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update 05/07/19  \n",
    "All plates finished and backed up (finished 05/03).  \n",
    "How to process (alternative approaches)\n",
    "\n",
    "1. K-means  \n",
    "2. PCA/UMAP (with louvain and leiden)  \n",
    "3. Unsupervised SVM  \n",
    "4. Spectral clustering  \n",
    "\n",
    "Benchmark all of them based on Pt04_r07_c05 (Incenp sgRNA1\t190219_195942-V\tG5)  \n",
    "\n",
    "### Update 05/16/19  \n",
    "Add also HDBSCAN  \n",
    "\n",
    "\n",
    "\n",
    "#### K-means.  \n",
    "Pre-trained AlexNet (described previously) run for 72 epochs to assign clusters for:  \n",
    "    \n",
    "    – Pt04_r07c05\n",
    "    – Pt04_r07c05\n",
    "    – Pt11_r02c12\n",
    "    \n",
    "Further training improved clustering with Louvain method (see `deepclust_multiple_samples.ipynb`).  \n",
    "\n",
    "\n",
    "### Update 05/20/19  \n",
    "\n",
    "#### Continuing training with PIC\n",
    "Launched another training of 102-epochs pre-trained alex net on the following:  \n",
    "```\n",
    "Haus8 sgRNA #1\t190219_195942-V\tB12\t\n",
    "Haus8 sgRNA #2\t190219_195942-V\tE1\t\n",
    "Haus8 sgRNA #3\t190219_195942-V\tF2\t\n",
    "Haus8 sgRNA #4\t190219_195942-V\tG2\t\n",
    "DyncH1 sgRNA #3\t190219_195942-V\tA1\t\n",
    "Incenp sgRNA #1\t190219_195942-V\tG4\t\n",
    "Incenp sgRNA #2\t190219_195942-V\tG6\t\n",
    "Incenp sgRNA #3\t190219_195942-V\tH1\t\n",
    "Rad21 sgRNA #1\t190219_195942-V\tH3\t\n",
    "Rad21 sgRNA #2\t190219_195942-V\tH5\t\n",
    "Rad21 sgRNA #3\t190219_195942-V\tH7\t\n",
    "```\n",
    "**NOTE** Testing PIC clustering for this one, since clusters are not balanced.\n",
    "\n",
    "**Conclusion** After 15 epochs of re-training shows a fair cluster separation on evaluation data. Level of abstarction seems lower than k-means training. Results in https://github.com/Gvaihir/image_sudoku/blob/master/deepclust_test_PIC15ep.ipynb  \n",
    "Started to train AlexNet with PIC further  \n",
    "\n",
    "\n",
    "#### Continuing training with Kmeans (total 300 epochs)  \n",
    "Launched another training of 102-epochs pre-trained alex net on the following:  \n",
    "```\n",
    "Haus8 sgRNA #1\t190219_195942-V\tB12\t\n",
    "Haus8 sgRNA #2\t190219_195942-V\tE1\t\n",
    "Haus8 sgRNA #3\t190219_195942-V\tF2\t\n",
    "Haus8 sgRNA #4\t190219_195942-V\tG2\t\n",
    "DyncH1 sgRNA #3\t190219_195942-V\tA1\t\n",
    "Incenp sgRNA #1\t190219_195942-V\tG4\t\n",
    "Incenp sgRNA #2\t190219_195942-V\tG6\t\n",
    "Incenp sgRNA #3\t190219_195942-V\tH1\t\n",
    "Rad21 sgRNA #1\t190219_195942-V\tH3\t\n",
    "Rad21 sgRNA #2\t190219_195942-V\tH5\t\n",
    "Rad21 sgRNA #3\t190219_195942-V\tH7\t\n",
    "```\n",
    "\n",
    "### Additional strategy  \n",
    "Extract features from multiple convolutional layers and cluster them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References  \n",
    "https://journals.aps.org/pre/pdf/10.1103/PhysRevE.80.056117 and https://www.nature.com/articles/srep30750 show Louvain to be most scalable  \n",
    "https://arxiv.org/pdf/1708.02898.pdf set of benchmarks. Also idea of multiple layers for feature extraction\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
