{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12881,
     "status": "ok",
     "timestamp": 1567623757993,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "yaAbb0QoeIIu",
    "outputId": "957a9375-9463-4110-b5e5-505b141b270a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3e/f0/c0d690d66be181ac74624fda68a53e3daf3008cf1a10702b957bf0a08420/wandb-0.8.9-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3MB 9.9MB/s \n",
      "\u001b[?25hCollecting python-dateutil>=2.6.1 (from wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/17/c62faccbfbd163c7f57f3844689e3a78bae1f403648a6afb1d0866d87fbb/python_dateutil-2.8.0-py2.py3-none-any.whl (226kB)\n",
      "\u001b[K     |████████████████████████████████| 235kB 55.2MB/s \n",
      "\u001b[?25hCollecting gql>=0.1.0 (from wandb)\n",
      "  Downloading https://files.pythonhosted.org/packages/aa/9c/2933b7791210e00f5c26a6243198cc03af9132c29cf85e4c22cb007f171e/gql-0.1.0.tar.gz\n",
      "Collecting watchdog>=0.8.3 (from wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/e3/5a55d48a29300160779f0a0d2776d17c1b762a2039b36de528b093b87d5b/watchdog-0.9.0.tar.gz (85kB)\n",
      "\u001b[K     |████████████████████████████████| 92kB 32.4MB/s \n",
      "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
      "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (2.21.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (1.12.0)\n",
      "Collecting GitPython>=1.0.0 (from wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/c7/70bd352e8a561a9b6d1cde9aa313b9d7c871b0c94c3821f44c01f3187e1d/GitPython-3.0.2-py3-none-any.whl (453kB)\n",
      "\u001b[K     |████████████████████████████████| 460kB 43.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.352.0)\n",
      "Collecting subprocess32>=3.5.3 (from wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 39.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (7.0)\n",
      "Collecting shortuuid>=0.5.0 (from wandb)\n",
      "  Downloading https://files.pythonhosted.org/packages/80/d7/2bfc9332e68d3e15ea97b9b1588b3899ad565120253d3fd71c8f7f13b4fe/shortuuid-0.5.0.tar.gz\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb) (5.4.8)\n",
      "Collecting sentry-sdk>=0.4.0 (from wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/02/313e94836ff56e4bec0e7343a1fcff6f3aa2d4a61b703d641e61bb0f306a/sentry_sdk-0.11.2-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 31.1MB/s \n",
      "\u001b[?25hCollecting graphql-core>=0.5.0 (from gql>=0.1.0->wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6a/11/bc4a7eb440124271289d93e4d208bd07d94196038fabbe2a52435a07d3d3/graphql_core-2.2.1-py2.py3-none-any.whl (250kB)\n",
      "\u001b[K     |████████████████████████████████| 256kB 58.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: promise>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from gql>=0.1.0->wandb) (2.2.1)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb) (3.13)\n",
      "Collecting argh>=0.24.1 (from watchdog>=0.8.3->wandb)\n",
      "  Downloading https://files.pythonhosted.org/packages/06/1c/e667a7126f0b84aaa1c56844337bf0ac12445d1beb9c8a6199a7314944bf/argh-0.26.2-py2.py3-none-any.whl\n",
      "Collecting pathtools>=0.1.1 (from watchdog>=0.8.3->wandb)\n",
      "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb) (2.8)\n",
      "Collecting gitdb2>=2.0.0 (from GitPython>=1.0.0->wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/da/30/a407568aa8d8f25db817cf50121a958722f3fc5f87e3a6fba1f40c0633e3/gitdb2-2.0.5-py2.py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 34.4MB/s \n",
      "\u001b[?25hCollecting rx<3,>=1.6 (from graphql-core>=0.5.0->gql>=0.1.0->wandb)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/0f/5ef4ac78e2a538cc1b054eb86285fe0bf7a5dbaeaac2c584757c300515e2/Rx-1.6.1-py2.py3-none-any.whl (179kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 59.3MB/s \n",
      "\u001b[?25hCollecting smmap2>=2.0.0 (from gitdb2>=2.0.0->GitPython>=1.0.0->wandb)\n",
      "  Downloading https://files.pythonhosted.org/packages/55/d2/866d45e3a121ee15a1dc013824d58072fd5c7799c9c34d01378eb262ca8f/smmap2-2.0.5-py2.py3-none-any.whl\n",
      "Building wheels for collected packages: gql, watchdog, subprocess32, shortuuid, pathtools\n",
      "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for gql: filename=gql-0.1.0-cp36-none-any.whl size=5541 sha256=5b7445bb9e68673c25f6fe6bd2f9e832197dfa3d99134eeae5d1dfd784d50ab3\n",
      "  Stored in directory: /root/.cache/pip/wheels/a7/8d/65/a3247f500d675d80a01e4d2f0ee44fe99f1faef575bc2a1664\n",
      "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for watchdog: filename=watchdog-0.9.0-cp36-none-any.whl size=73652 sha256=271feb773c1f7b9dcc2b4ad8ff410932502e0e957ab1febea48a2f9ecc890dbc\n",
      "  Stored in directory: /root/.cache/pip/wheels/61/1d/d0/04cfe495619be2095eb8d89a31c42adb4e42b76495bc8f784c\n",
      "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=ed336db8f03fd287c9d4bd605c47fb9586a7e959840c4a81299b2ee6207d08fa\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
      "  Building wheel for shortuuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for shortuuid: filename=shortuuid-0.5.0-cp36-none-any.whl size=5499 sha256=1d9d3b8059b1707d6f9cfb4b880fdb9270b773a75a3932cd561af4886056188a\n",
      "  Stored in directory: /root/.cache/pip/wheels/3f/eb/fd/69e5177f67b505e44acbd1aedfbe44b91768ee0c4cd5636576\n",
      "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8786 sha256=36c7be9ec261a6184d61e7bddf019af470c344bf340315f20098559bd7598da2\n",
      "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
      "Successfully built gql watchdog subprocess32 shortuuid pathtools\n",
      "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
      "Installing collected packages: python-dateutil, rx, graphql-core, gql, argh, pathtools, watchdog, docker-pycreds, smmap2, gitdb2, GitPython, subprocess32, shortuuid, sentry-sdk, wandb\n",
      "  Found existing installation: python-dateutil 2.5.3\n",
      "    Uninstalling python-dateutil-2.5.3:\n",
      "      Successfully uninstalled python-dateutil-2.5.3\n",
      "Successfully installed GitPython-3.0.2 argh-0.26.2 docker-pycreds-0.4.0 gitdb2-2.0.5 gql-0.1.0 graphql-core-2.2.1 pathtools-0.1.2 python-dateutil-2.8.0 rx-1.6.1 sentry-sdk-0.11.2 shortuuid-0.5.0 smmap2-2.0.5 subprocess32-3.5.4 wandb-0.8.9 watchdog-0.9.0\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "pip_warning": {
        "packages": [
         "dateutil"
        ]
       }
      }
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gilTWBjWlqnt"
   },
   "outputs": [],
   "source": [
    "!mkdir data\n",
    "!unzip normal_1k.zip\n",
    "!mv normal data/\n",
    "\n",
    "#!unzip data/negative.zip \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2422,
     "status": "ok",
     "timestamp": 1567623775265,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "D9XhRL4kd8VJ",
    "outputId": "9ffd9711-dea3-438f-d8f2-870af3566a88"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "from argparse import RawTextHelpFormatter\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# keras\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Reshape, UpSampling2D, Conv2DTranspose, Flatten, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import plot_model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "from absl import app\n",
    "\n",
    "# logging\n",
    "import wandb\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9kgDkyfeeCEq"
   },
   "outputs": [],
   "source": [
    "def create_model(input_dim, latent_dim, verbose=False, save_graph=False, conv=True,\n",
    "                 adversarial=True):\n",
    "    '''\n",
    "    Creates model\n",
    "    :param input_dim: tuple, dmensions of an image (w*h*ch). W and H has to give modulo of division by 8 = 0\n",
    "    :param latent_dim: int, number of latent dimensions\n",
    "    :param verbose: bool, chatty\n",
    "    :param save_graph: bool, saves latent representation. Work only for 2d latent\n",
    "    :param conv: bool, make convolutional model\n",
    "    :param adversarial: bool, make adversarial model\n",
    "    :return: autoencoder, (discriminator), (generator), encoder, decoder\n",
    "    '''\n",
    "    assert input_dim[0]%8 == 0, \"Dimension error: Chose H and W dimensions that can be divided by 8 without remnant\"\n",
    "    autoencoder_input = Input(shape=input_dim)\n",
    "    generator_input = Input(shape=input_dim)\n",
    "    reshape_dim = int(input_dim[0] / (2 ** 3))\n",
    "    if conv:\n",
    "        # Assemble convolutional model\n",
    "        encoder = Sequential()\n",
    "        encoder.add(Conv2D(256, kernel_size=(5, 5), input_shape=input_dim, padding='same', activation='relu',\n",
    "                           data_format=\"channels_last\"))\n",
    "        encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        encoder.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001))\n",
    "        encoder.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "        encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        encoder.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001))\n",
    "        encoder.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "        encoder.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "        encoder.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001))\n",
    "        encoder.add(Flatten())\n",
    "        encoder.add(Dense(reshape_dim**2*16, activation='relu'))  # different, was 256\n",
    "        encoder.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001))\n",
    "        encoder.add(Dense(reshape_dim**2*16, activation='relu'))  # different, didn't exist\n",
    "        encoder.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001))\n",
    "        encoder.add(Dense(latent_dim, activation=None))  # different (was reshaping to 64D)\n",
    "        \n",
    "        decoder = Sequential()\n",
    "        decoder.add(Dense(reshape_dim**2*16, input_shape=(latent_dim,), activation='relu'))\n",
    "        decoder.add(Dense(reshape_dim**2*16, activation='relu'))\n",
    "        decoder.add(Dense(reshape_dim**2*32, activation='relu'))\n",
    "        decoder.add(Reshape((reshape_dim, reshape_dim, 32)))\n",
    "        decoder.add(UpSampling2D((2, 2)))\n",
    "        decoder.add(Conv2DTranspose(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "        decoder.add(UpSampling2D((2, 2)))\n",
    "        decoder.add(Conv2DTranspose(32, kernel_size=(3, 3), padding='same', activation='relu'))\n",
    "        decoder.add(UpSampling2D((2, 2)))\n",
    "        decoder.add(Conv2DTranspose(3, kernel_size=(5, 5), padding='same', activation='sigmoid')) # Relu in CellCognition\n",
    "        if adversarial:\n",
    "            discriminator = Sequential()\n",
    "            discriminator.add(Dense(reshape_dim**2*16, input_shape=(latent_dim,), activation='relu'))\n",
    "            discriminator.add(Dense(reshape_dim**2*16, activation='relu'))\n",
    "            discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    else:\n",
    "        encoder = Sequential()\n",
    "        encoder.add(Dense(reshape_dim**2*16, input_shape=input_dim, activation='relu'))\n",
    "        encoder.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001))\n",
    "        encoder.add(Dense(reshape_dim**2*16, activation='relu'))\n",
    "        encoder.add(BatchNormalization(axis=-1, momentum=0.9, epsilon=0.001))\n",
    "        encoder.add(Dense(latent_dim, activation=None))\n",
    "        decoder = Sequential()\n",
    "        decoder.add(Dense(reshape_dim**2*16, input_shape=(latent_dim,), activation='relu'))\n",
    "        decoder.add(Dense(reshape_dim**2*16, activation='relu'))\n",
    "        decoder.add(Reshape((reshape_dim, reshape_dim, 3)))\n",
    "        decoder.add(Dense(input_dim, activation='sigmoid'))\n",
    "        if adversarial:\n",
    "            discriminator = Sequential()\n",
    "            discriminator.add(Dense(1600, input_shape=(latent_dim,), activation='relu'))\n",
    "            discriminator.add(Dense(1000, activation='relu'))\n",
    "            discriminator.add(Dense(1, activation='sigmoid'))\n",
    "    autoencoder = Model(autoencoder_input, decoder(encoder(autoencoder_input)))\n",
    "    autoencoder.compile(optimizer=Adam(lr=1e-4), loss=\"mean_squared_error\", metrics=['accuracy'])\n",
    "    if adversarial:\n",
    "        discriminator.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "        discriminator.trainable = False\n",
    "        generator = Model(generator_input, discriminator(encoder(generator_input)))\n",
    "        generator.compile(optimizer=Adam(lr=1e-4), loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
    "    if verbose:\n",
    "        print(\"Autoencoder Architecture\")\n",
    "        print(autoencoder.summary())\n",
    "        if adversarial:\n",
    "            print(\"Discriminator Architecture\")\n",
    "            print(discriminator.summary())\n",
    "            print(\"Generator Architecture\")\n",
    "            print(generator.summary())\n",
    "    if save_graph:\n",
    "        plot_model(autoencoder, to_file=\"autoencoder_graph.png\")\n",
    "        if adversarial:\n",
    "            plot_model(discriminator, to_file=\"discriminator_graph.png\")\n",
    "            plot_model(generator, to_file=\"generator_graph.png\")\n",
    "    if adversarial:\n",
    "        return autoencoder, discriminator, generator, encoder, decoder\n",
    "    else:\n",
    "        return autoencoder, None, None, encoder, decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4AVMwuq6eKOh"
   },
   "outputs": [],
   "source": [
    "\n",
    "def train(train_data, out, latent_dim, n_epochs, autoencoder, discriminator, generator, encoder, decoder,\n",
    "          adversarial = True):\n",
    "    '''\n",
    "    Function to train autoencoder. Arguments will be taken from argparse\n",
    "    :param train_data: input data from flow_from_directory\n",
    "    :param out: dir to save the models\n",
    "    :param latent_dim: number of latent dimensions\n",
    "    :param n_epochs: Number of epochs\n",
    "    :param autoencoder: created autoencoder model\n",
    "    :param discriminator: created discriminator model\n",
    "    :param generator: created generator model\n",
    "    :param encoder: created encoder part of autoencoder\n",
    "    :param decoder: created decoder part of autoencoder\n",
    "    :param adversarial: make adversarial model\n",
    "    :return: trained encoder, decoder, discriminator and generator\n",
    "    '''\n",
    "    for epoch in np.arange(1, n_epochs + 1):\n",
    "        autoencoder_losses = []\n",
    "        if adversarial:\n",
    "            discriminator_losses = []\n",
    "            generator_losses = []\n",
    "        autoencoder_history = autoencoder.fit_generator(train_data, epochs=1)\n",
    "        if adversarial:\n",
    "            batch_index = 0\n",
    "            discriminator_batch_losses = []\n",
    "            generator_batch_losses = []\n",
    "            while batch_index <= train_data.batch_index:\n",
    "                data = train_data.next()\n",
    "                data_list = data[0]\n",
    "                data_size = len(data_list)\n",
    "                fake_latent = encoder.predict(data_list)\n",
    "                discriminator_input = np.concatenate((fake_latent, np.random.randn(data_size, latent_dim) * 5.))\n",
    "                discriminator_labels = np.concatenate((np.zeros((data_size, 1)), np.ones((data_size, 1))))\n",
    "                discriminator_history = discriminator.fit(x=discriminator_input, y=discriminator_labels, epochs=1,\n",
    "                                                          batch_size=data_size, validation_split=0.0, verbose=0)\n",
    "                generator_history = generator.fit(data_list, y=np.ones((data_size, 1)), epochs=1,\n",
    "                                                  batch_size=data_size, validation_split=0.0, verbose=0)\n",
    "                batch_index = batch_index + 1\n",
    "                discriminator_batch_losses.append(discriminator_history.history[\"loss\"])\n",
    "                generator_batch_losses.append(generator_history.history[\"loss\"])\n",
    "        autoencoder_losses.append(autoencoder_history.history[\"loss\"])\n",
    "        # WandB logging\n",
    "        if adversarial:\n",
    "            discriminator_losses.append(np.mean(discriminator_batch_losses))\n",
    "            generator_losses.append(np.mean(generator_batch_losses))\n",
    "            print(\"generator_loss = {}\\n\"\n",
    "                  \"generator_acc = {}\".format(\n",
    "                generator_history.history[\"loss\"],\n",
    "                generator_history.history[\"acc\"]\n",
    "            ))\n",
    "            # WandB logging\n",
    "            wandb.log({\"phase\": epoch,\n",
    "                       \"ae_train_loss\": autoencoder_history.history[\"loss\"],\n",
    "                       \"ae_train_acc\": autoencoder_history.history[\"acc\"],\n",
    "                       \"gen_train_loss\": generator_history.history[\"loss\"],\n",
    "                       \"gen_train_acc\": generator_history.history[\"acc\"]}, step=epoch)\n",
    "        else:\n",
    "            wandb.log({\"phase\": epoch,\n",
    "                       \"ae_train_loss\": autoencoder_history.history[\"loss\"],\n",
    "                       \"ae_train_acc\": autoencoder_history.history[\"acc\"]}, step=epoch)\n",
    "        if epoch % 50 == 0:\n",
    "            print(\"\\nSaving models...\")\n",
    "            encoder.save(os.path.join(out, 'encoder.h5'))\n",
    "            decoder.save(os.path.join(out, 'decoder.h5'))\n",
    "            if adversarial:\n",
    "                discriminator.save(os.path.join(out, 'discriminator.h5'))\n",
    "                generator.save(os.path.join(out, 'generator.h5'))\n",
    "    encoder.save(os.path.join(out, 'encoder.h5'))\n",
    "    decoder.save(os.path.join(out, 'decoder.h5'))\n",
    "    if adversarial:\n",
    "        discriminator.save(os.path.join(out, 'discriminator.h5'))\n",
    "        generator.save(os.path.join(out, 'generator.h5'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 888,
     "status": "ok",
     "timestamp": 1567625265414,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "SVFZQwCCqGFh",
    "outputId": "17a1a4c1-8b88-4667-c105-1f7a800c0ad3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/gvaihir_ucsf/image_sudoku/runs/7r97q6xz\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
       "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "W&B Run: https://app.wandb.ai/gvaihir_ucsf/image_sudoku/runs/7r97q6xz"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_wd = \"/home/aogorodnikov/data_aae\"\n",
    "batch = 56\n",
    "input_dim = (104,104,3)\n",
    "latent_dim = 32\n",
    "epoch = 10\n",
    "conv=True\n",
    "adversarial=True\n",
    "out=\"~/aae/\"\n",
    "# initialize monitoring with WandB\n",
    "wandb.init()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2267,
     "status": "ok",
     "timestamp": 1567625267255,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "bVxqIdpvtQez",
    "outputId": "c20ae7e3-1698-4211-c150-32012eaf6170"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Autoencoder Architecture\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 104, 104, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32)                22069760  \n",
      "_________________________________________________________________\n",
      "sequential_2 (Sequential)    (None, 104, 104, 3)       22053091  \n",
      "=================================================================\n",
      "Total params: 44,122,851\n",
      "Trainable params: 44,111,843\n",
      "Non-trainable params: 11,008\n",
      "_________________________________________________________________\n",
      "None\n",
      "Discriminator Architecture\n",
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 2704)              89232     \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 2704)              7314320   \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 2705      \n",
      "=================================================================\n",
      "Total params: 14,812,514\n",
      "Trainable params: 7,406,257\n",
      "Non-trainable params: 7,406,257\n",
      "_________________________________________________________________\n",
      "None\n",
      "Generator Architecture\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 104, 104, 3)       0         \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 32)                22069760  \n",
      "_________________________________________________________________\n",
      "sequential_3 (Sequential)    (None, 1)                 7406257   \n",
      "=================================================================\n",
      "Total params: 29,476,017\n",
      "Trainable params: 22,058,752\n",
      "Non-trainable params: 7,417,265\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras/engine/training.py:493: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "autoencoder, discriminator, generator, encoder, decoder = create_model(input_dim=input_dim,\n",
    "                                                                           latent_dim=latent_dim,\n",
    "                                                                           verbose=True, save_graph=False,\n",
    "                                                                           conv=conv,\n",
    "                                                                           adversarial=adversarial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 902,
     "status": "ok",
     "timestamp": 1567626545559,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "9hNHkaOF19wk",
    "outputId": "c0a0794a-a86f-491a-a25c-540bf83c3a27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1083 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# LOAD DATA\n",
    "data_loader = ImageDataGenerator(\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_data = data_loader.flow_from_directory(\n",
    "    img_wd,\n",
    "    target_size=(input_dim[0], input_dim[0]),\n",
    "    batch_size=batch,\n",
    "    class_mode='input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 73762,
     "status": "error",
     "timestamp": 1567624170992,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "MIJbKxRXyRHz",
    "outputId": "3b3df656-76e0-4fdb-f651-eabfdbad615f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 29s 1s/step - loss: 946.0207 - acc: 0.5277\n",
      "generator_loss = [2.8725650310516357]\n",
      "generator_acc = [0.05263157933950424]\n",
      "Epoch 1/1\n",
      "20/20 [==============================] - 25s 1s/step - loss: 929.9670 - acc: 0.5463\n",
      "generator_loss = [3.6901795864105225]\n",
      "generator_acc = [0.05263157933950424]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Wandb version 0.8.13 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/home/aogorodnikov/anaconda3/envs/imgSudoku/lib/python3.7/site-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4/20 [=====>........................] - ETA: 24s - loss: 954.8622 - acc: 0.5529"
     ]
    }
   ],
   "source": [
    "# training mode\n",
    "train(train_data=train_data, out=out,\n",
    "    latent_dim=latent_dim, n_epochs=epoch,\n",
    "    autoencoder=autoencoder, discriminator=discriminator,\n",
    "    generator=generator, encoder=encoder, decoder=decoder,\n",
    "    adversarial=adversarial)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 196623,
     "status": "ok",
     "timestamp": 1567625686062,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "4m24vkpomnoc",
    "outputId": "02aa1bef-3609-497a-f799-da08260e6dc2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        Notebook configured with <a href=\"https://wandb.com\" target=\"_blank\">W&B</a>. You can <a href=\"https://app.wandb.ai/gvaihir_ucsf/uncategorized/runs/8j1n8tnx\" target=\"_blank\">open</a> the run page, or call <code>%%wandb</code>\n",
       "        in a cell containing your training loop to display live results.  Learn more in our <a href=\"https://docs.wandb.com/docs/integrations/jupyter.html\" target=\"_blank\">docs</a>.\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 4s 193ms/step - loss: 931.7775 - acc: 0.5512\n",
      "Epoch 2/50\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 927.2318 - acc: 0.5524\n",
      "Epoch 3/50\n",
      "20/20 [==============================] - 4s 188ms/step - loss: 928.3882 - acc: 0.5489\n",
      "Epoch 4/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 931.7396 - acc: 0.5512\n",
      "Epoch 5/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 934.5702 - acc: 0.5494\n",
      "Epoch 6/50\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 928.8546 - acc: 0.5516\n",
      "Epoch 7/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 927.5276 - acc: 0.5517\n",
      "Epoch 8/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 934.0972 - acc: 0.5487\n",
      "Epoch 9/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 928.8567 - acc: 0.5498\n",
      "Epoch 10/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 934.8931 - acc: 0.5468\n",
      "Epoch 11/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 927.2352 - acc: 0.5493\n",
      "Epoch 12/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 923.3691 - acc: 0.5489\n",
      "Epoch 13/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 931.7276 - acc: 0.5506\n",
      "Epoch 14/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 931.5499 - acc: 0.5504\n",
      "Epoch 15/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 932.7969 - acc: 0.5500\n",
      "Epoch 16/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 927.5341 - acc: 0.5503\n",
      "Epoch 17/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 931.0230 - acc: 0.5506\n",
      "Epoch 18/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 924.9424 - acc: 0.5520\n",
      "Epoch 19/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 930.4654 - acc: 0.5521\n",
      "Epoch 20/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 925.4891 - acc: 0.5539\n",
      "Epoch 21/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 927.4817 - acc: 0.5511\n",
      "Epoch 22/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 926.7244 - acc: 0.5518\n",
      "Epoch 23/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 928.6160 - acc: 0.5504\n",
      "Epoch 24/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 927.2426 - acc: 0.5488\n",
      "Epoch 25/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 927.3219 - acc: 0.5483\n",
      "Epoch 26/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 929.4128 - acc: 0.5533\n",
      "Epoch 27/50\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 937.0386 - acc: 0.5497\n",
      "Epoch 28/50\n",
      "20/20 [==============================] - 4s 201ms/step - loss: 925.2019 - acc: 0.5528\n",
      "Epoch 29/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 925.0856 - acc: 0.5528\n",
      "Epoch 30/50\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 930.2220 - acc: 0.5503\n",
      "Epoch 31/50\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 930.1215 - acc: 0.5501\n",
      "Epoch 32/50\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 926.6226 - acc: 0.5516\n",
      "Epoch 33/50\n",
      "20/20 [==============================] - 4s 189ms/step - loss: 931.8215 - acc: 0.5527\n",
      "Epoch 34/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 930.7149 - acc: 0.5504\n",
      "Epoch 35/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 924.5757 - acc: 0.5529\n",
      "Epoch 36/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 928.2757 - acc: 0.5553\n",
      "Epoch 37/50\n",
      "20/20 [==============================] - 4s 190ms/step - loss: 930.3688 - acc: 0.5513\n",
      "Epoch 38/50\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 938.2127 - acc: 0.5519\n",
      "Epoch 39/50\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 920.4588 - acc: 0.5482\n",
      "Epoch 40/50\n",
      "20/20 [==============================] - 4s 194ms/step - loss: 934.2994 - acc: 0.5530\n",
      "Epoch 41/50\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 931.4027 - acc: 0.5499\n",
      "Epoch 42/50\n",
      "20/20 [==============================] - 4s 192ms/step - loss: 926.9267 - acc: 0.5523\n",
      "Epoch 43/50\n",
      "20/20 [==============================] - 4s 191ms/step - loss: 931.1888 - acc: 0.5519\n",
      "Epoch 44/50\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 927.9032 - acc: 0.5536\n",
      "Epoch 45/50\n",
      "20/20 [==============================] - 4s 193ms/step - loss: 930.4241 - acc: 0.5508\n",
      "Epoch 46/50\n",
      "20/20 [==============================] - 4s 197ms/step - loss: 935.6559 - acc: 0.5493\n",
      "Epoch 47/50\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 928.0855 - acc: 0.5521\n",
      "Epoch 48/50\n",
      "20/20 [==============================] - 4s 196ms/step - loss: 929.4493 - acc: 0.5519\n",
      "Epoch 49/50\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 926.2640 - acc: 0.5523\n",
      "Epoch 50/50\n",
      "20/20 [==============================] - 4s 195ms/step - loss: 940.3848 - acc: 0.5513\n"
     ]
    }
   ],
   "source": [
    "wandb.init(config={\"hyper\": \"parameter\"})\n",
    "autoencoder_history = autoencoder.fit_generator(train_data, epochs=50, callbacks=[WandbCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lp4c3hxtmp3g"
   },
   "outputs": [],
   "source": [
    "from wandb.keras import WandbCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 806,
     "status": "ok",
     "timestamp": 1567547376299,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "PP_qDCVJ4nv5",
    "outputId": "800c1d90-bb1b-450d-ed31-5742347ec8d1"
   },
   "outputs": [],
   "source": [
    "print(\"generator_loss = {}\\n\"\n",
    "                  \"generator_acc = {}\".format(\n",
    "                generator_history.history[\"loss\"],\n",
    "                generator_history.history[\"acc\"]\n",
    "            ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9YMtkisKGj3I"
   },
   "outputs": [],
   "source": [
    "generator_history = generator.fit(data_list, y=np.ones((data_size, 1)), epochs=1,\n",
    "                                                  batch_size=data_size, validation_split=0.0, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 80
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3296,
     "status": "ok",
     "timestamp": 1567583452813,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "K5tj2_etGpK1",
    "outputId": "a50f77c7-8676-4a8a-dce1-c76bc4b8d8c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "2.2.5\n"
     ]
    }
   ],
   "source": [
    "!python -c 'import keras; print(keras.__version__)'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FAsUgG3lQTFb"
   },
   "outputs": [],
   "source": [
    "def draw(samples):\n",
    "    fig = plt.figure(figsize=(5 * len(samples), 5))\n",
    "    gs = gridspec.GridSpec(1, len(samples))\n",
    "    for i, sample in enumerate(samples):\n",
    "        ax = plt.Subplot(fig, gs[i])\n",
    "        ax.imshow((sample[\"image\"] * 255.).reshape(28, 28), cmap='gray')\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        ax.set_aspect('equal')\n",
    "        ax.set_title(sample[\"title\"])\n",
    "        fig.add_subplot(ax)\n",
    "    plt.show(block=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 577,
     "status": "error",
     "timestamp": 1567627691383,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "ALTMp6f-yd8w",
    "outputId": "069449c1-4646-4c5e-8c0f-0af8a3a1d1da"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-8a9d03ace80e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnormalize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moriginal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mlatent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mreconstruction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlatent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Original\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moriginal\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"title\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"Reconstruction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"image\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mreconstruction\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1378\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    755\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    758\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    129\u001b[0m                         \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' dimensions, but got array '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[1;32m    132\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected conv2d_10_input to have 4 dimensions, but got array with shape (3, 104, 104)"
     ]
    }
   ],
   "source": [
    "choice = np.random.choice(np.arange(9))\n",
    "original = data_list[choice].reshape(3,104,104)\n",
    "normalize = colors.Normalize(0., 255.)\n",
    "original = normalize(original)\n",
    "latent = encoder.predict(original)\n",
    "reconstruction = decoder.predict(latent)\n",
    "draw([{\"title\": \"Original\", \"image\": original}, {\"title\": \"Reconstruction\", \"image\": reconstruction}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 505
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 848,
     "status": "ok",
     "timestamp": 1567626649301,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "0ZvLjPtW1BkF",
    "outputId": "2c7df2ed-6904-4a08-99a5-37f6857f5861"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:716: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "/usr/local/lib/python3.6/dist-packages/keras_preprocessing/image/image_data_generator.py:724: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    }
   ],
   "source": [
    "data = train_data.next()\n",
    "data_list = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1079,
     "status": "ok",
     "timestamp": 1567627666202,
     "user": {
      "displayName": "Gvaihir Croft",
      "photoUrl": "",
      "userId": "10363069317116357320"
     },
     "user_tz": 420
    },
    "id": "en45t8AN1Fs9",
    "outputId": "527ca76a-9b51-449e-8fca-dbd88f1d167c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "125.31762"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data_list[2].reshape(3,104,104)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EWPWhW6w46ad"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled5.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
